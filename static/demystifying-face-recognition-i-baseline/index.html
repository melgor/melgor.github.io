<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Demystifying Face Recognition I: Baseline</title>
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link rel="stylesheet" type="text/css" href="../assets/built/screen.css?v=503d750ec5">

    <link rel="shortcut icon" href="../favicon.ico" type="image/x-icon">
    <link rel="canonical" href="index.html">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <link rel="amphtml" href="amp/index.html">
    
    <meta property="og:site_name" content="BLCV">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Demystifying Face Recognition I: Baseline">
    <meta property="og:description" content="Test różnych architektur sieci Zgodnie z założeniami, mamy gotową bazę danych (CASIA-WebFace), zdefiniowany obraz wejściowy  (112x96) oraz DA jako mirror, a całość będzie traktowana jako zadanie klasyfikacji. Czyli ostatnim elementem, który został nam to wybór architektektury. Ostatnie lata obfitowały w wiele różnorodnych technik, takich jak ResNet, Inception, DenseNet czy Inception-ResNet.">
    <meta property="og:url" content="http://localhost:2368/demystifying-face-recognition-i-baseline/">
    <meta property="og:image" content="http://localhost:2368/content/images/2017/10/faceresnet.png">
    <meta property="article:published_time" content="2017-10-07T05:29:36.000Z">
    <meta property="article:modified_time" content="2017-10-07T05:29:36.000Z">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Demystifying Face Recognition I: Baseline">
    <meta name="twitter:description" content="Test różnych architektur sieci Zgodnie z założeniami, mamy gotową bazę danych (CASIA-WebFace), zdefiniowany obraz wejściowy  (112x96) oraz DA jako mirror, a całość będzie traktowana jako zadanie klasyfikacji. Czyli ostatnim elementem, który został nam to wybór architektektury. Ostatnie lata obfitowały w wiele różnorodnych technik, takich jak ResNet, Inception, DenseNet czy Inception-ResNet.">
    <meta name="twitter:url" content="http://localhost:2368/demystifying-face-recognition-i-baseline/">
    <meta name="twitter:image" content="http://localhost:2368/content/images/2017/10/faceresnet.png">
    <meta name="twitter:label1" content="Written by">
    <meta name="twitter:data1" content="Bartosz Ludwiczuk">
    <meta property="og:image:width" content="689">
    <meta property="og:image:height" content="93">
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "BLCV",
        "logo": "https://casper.ghost.org/v1.0.0/images/ghost-logo.svg"
    },
    "author": {
        "@type": "Person",
        "name": "Bartosz Ludwiczuk",
        "url": "http://localhost:2368/author/bartosz/",
        "sameAs": []
    },
    "headline": "Demystifying Face Recognition I: Baseline",
    "url": "http://localhost:2368/demystifying-face-recognition-i-baseline/",
    "datePublished": "2017-10-07T05:29:36.000Z",
    "dateModified": "2017-10-07T05:29:36.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "http://localhost:2368/content/images/2017/10/faceresnet.png",
        "width": 689,
        "height": 93
    },
    "description": "Test różnych architektur sieci Zgodnie z założeniami, mamy gotową bazę danych (CASIA-WebFace), zdefiniowany obraz wejściowy  (112x96) oraz DA jako mirror, a całość będzie traktowana jako zadanie klasyfikacji. Czyli ostatnim elementem, który został nam to wybór architektektury. Ostatnie lata obfitowały w wiele różnorodnych technik, takich jak ResNet, Inception, DenseNet czy Inception-ResNet.",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "http://localhost:2368/"
    }
}
    </script>

    <script type="text/javascript" src="../public/ghost-sdk.js?v=503d750ec5"></script>
<script type="text/javascript">
ghost.init({
	clientId: "ghost-frontend",
	clientSecret: "867ed4731917"
});
</script>
    <meta name="generator" content="Ghost 1.8">
    <link rel="alternate" type="application/rss+xml" title="BLCV" href="../rss/index.html">

</head>
<body class="post-template">

    <div class="site-wrapper">

        

<header class="site-header outer">
    <div class="inner">
        <nav class="site-nav">
    <div class="site-nav-left">
                <a class="site-nav-logo" href="../"><img src="https://casper.ghost.org/v1.0.0/images/ghost-logo.svg" alt="BLCV"></a>
            <ul class="nav">
    <li class="nav-home" role="presentation"><a href="../">Home</a></li>
</ul>
    </div>
    <div class="site-nav-right">
        <div class="social-links">
        </div>
            <a class="rss-button" href="http://cloud.feedly.com/#subscription/feed/http://localhost:2368/rss/" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><circle cx="6.18" cy="17.82" r="2.18"></circle><path d="M4 4.44v2.83c7.03 0 12.73 5.7 12.73 12.73h2.83c0-8.59-6.97-15.56-15.56-15.56zm0 5.66v2.83c3.9 0 7.07 3.17 7.07 7.07h2.83c0-5.47-4.43-9.9-9.9-9.9z"></path></svg>
</a>
    </div>
</nav>
    </div>
</header>


<main id="site-main" class="site-main outer" role="main">
    <div class="inner">

        <article class="post-full post ">

            <header class="post-full-header">
                <section class="post-full-meta">
                    <time class="post-full-meta-date" datetime="2017-10-07">7 October 2017</time>
                </section>
                <h1 class="post-full-title">Demystifying Face Recognition I: Baseline</h1>
            </header>

            <figure class="post-full-image" style="background-image: url(../content/images/2017/10/faceresnet.png)">
            </figure>

            <section class="post-full-content">
                <div class="kg-card-markdown"><h1 id="testrnycharchitektursieci">Test różnych architektur sieci</h1>
<p>Zgodnie z założeniami, mamy gotową bazę danych (CASIA-WebFace), zdefiniowany obraz wejściowy  (112x96) oraz DA jako <code>mirror</code>, a całość będzie traktowana jako zadanie klasyfikacji. Czyli ostatnim elementem, który został nam to wybór architektektury. Ostatnie lata obfitowały w wiele różnorodnych technik, takich jak <code>ResNet</code>, <code>Inception</code>, <code>DenseNet</code> czy <code>Inception-ResNet</code>. Także w artykułach dotyczących Rozpoznawania Twarzy, autorzy proponowali własne wersje architektur. Obecnie skupimy się właśnie na tych ostatnich, głównie dlatego, że wiemy jaką jakość możemy z nich uzyskać oraz z powodu mniejszego liczby obliczeń. Przeanalizujemy także starsze architektury, aby pokazać czy struktury sieci mają aż takie znaczenie. Do dokładniejszych badań dotyczących architektury wrócimy, gdy przygotojemy dane wejściowe, operacje Data-Augumentation oraz funkcje celu (które także mogą służyć jako regularyzator).</p>
<h2 id="opisarchitektur">Opis Architektur</h2>
<p><strong><a href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf">LeNet</a></strong> - Pierwsza konwolucyjna architektura wykorzystywana do przetwarzania obrazów. Wejściowy obraz: 28x24.</p>
<p><strong><a href="http://mmlab.ie.cuhk.edu.hk/pdf/YiSun_CVPR14.pdf">DeepID</a></strong> - Jedna z pierwszych wyspecjalizowanych sieć wykorzystywanych do ‘Rozpoznawania twarzy’. Moc została zwiększona zwiększenie liczby filtrów oraz połączenie cech z dwóch warstw konwolucyjnych. Wejściowy rozmiar: 42x36.</p>
<p><strong><a href="https://arxiv.org/abs/1412.1265">DeepID2+</a></strong> - Rozszerzona wersja DeepID, posiada jeszcze większą liczbę filtrów oraz rozmiar końcowych cech został zwiększony do 512. Wejściowy rozmiar: 56x48.</p>
<p><strong><a href="https://arxiv.org/abs/1411.7923">Casia-Net</a></strong> - Sieć zaproponowana po pierwszych sukcesach VGG i GoogLeNet w konkursie ImageNet. Wykorzystuje koncept rozmiarów kerneli 3x3 oraz ‘Averege Pooling’.</p>
<p><strong><a href="https://arxiv.org/abs/1511.02683">Light-CNN</a></strong>- Propozycja sieci wykorzystująca ‘MFM’ jako funkcję aktywacji. Autor wykazał, że sprawuje się o wiele lepiej niż ReLU, ELU czy PReLU.</p>
<p><strong><a href="https://arxiv.org/abs/1611.08976">FaceResNet</a></strong> - Sieć zaproponowana przez autorów artykułów CenterLoss i RangeLoss, która wykorzystuje połączenia ‘resiudualne’, tak jak w ‘ResNet’. Nie wykorzystuje warstw ‘BatchNorm’ oraz zastępuje funkcje aktywacji ‘Relu’ funkcjami ‘PRelu’.</p>
<p><strong><a href="https://arxiv.org/abs/1704.08063">SphereFace</a></strong> - Nowa wersja FaceResNet, którą główną zmianą jest usunięcie modułów MaxPool przez Konwolucje ze krokiem równym 2.</p>
<p><strong><a href="http://www.yugangjiang.info/publication/icmr17-face.pdf">Fudan-Arch</a></strong> - idea FaceResNet z BatchNorm. Autorzy zaproponowali dwie wersje sieci, Fast i Full model, różniącą się liczbą modułów w połączeniu residualnym.</p>
<p>W większości przedstawonym powyżej architektur, jednym ze składników jest DropOut. Na obecnym etapie wolałbym uniknąć jego załączania, ale ze względu na walidację implementacji oraz możliwości sieci, każda z architektur zostanie przetestowana w dwóch wariantach: podstawowej oraz z Dropout. Do oceny każdej sieci wykorzystamy jej wyniki jakościowe (jak dokładność czy koszt) oraz parametry określajace czas do uzyskania wyniku. Model każdej z architekur został wybrany na podstawie modelu o najniższym walidacyjnym koszcie, czyli wynik LFW nie wpływał na wybór modelu, mimo że modele uzyskiwały lepsze rezultaty w innej epoce.</p>
<h2 id="wyniki">Wyniki</h2>
<iframe width="840" height="790" frameborder="0" scrolling="no" src="http://plot.ly/~melgor89/92.embed"></iframe>
<div>
    <a href="https://plot.ly/~melgor89/98/?share_key=VSxvwfjwCjfc4arfLtqkce" target="_blank" title="blog1-plot-pure" style="display: block; text-align: center;"><img src="https://plot.ly/~melgor89/98.png?share_key=VSxvwfjwCjfc4arfLtqkce" alt="blog1-plot-pure" style="max-width: 100%;width: 800px;" width="800" onerror="this.onerror=null;this.src='https://plot.ly/404.png';"></a>
    <script data-plotly="melgor89:98" sharekey-plotly="VSxvwfjwCjfc4arfLtqkce" src="https://plot.ly/embed.js" async></script>
</div>
<div>
    <a href="https://plot.ly/~melgor89/97/?share_key=Yn4LoxjBIG2zd42I8KMEfG" target="_blank" title="blog1-plot-dropout" style="display: block; text-align: center;"><img src="https://plot.ly/~melgor89/97.png?share_key=Yn4LoxjBIG2zd42I8KMEfG" alt="blog1-plot-dropout" style="max-width: 100%;width: 800px;" width="800" onerror="this.onerror=null;this.src='https://plot.ly/404.png';"></a>
    <script data-plotly="melgor89:97" sharekey-plotly="Yn4LoxjBIG2zd42I8KMEfG" src="https://plot.ly/embed.js" async></script>
</div>
<h2 id="ocenajakociarchitektur">Ocena jakości Architektur</h2>
<p>Najpierw ocenimy architektury zawierające DropOut. Najlepszy wynik pod względem jakości na zbiorze walidacyjnym (~0.94) jak i na LFW (~0.98) uzyskują architektury Fudan. Następnie architektury SphereFace, FaceResNet, Light-CNN oraz CASIA uzyskują podobną jakość na zbiorze LFW (~0.97), jednak ich jakość na zbiorze walidacyjnym jest różna (od ~1.3 do ~1.0).  Można to zinterpretować, że cechy produkowane przez każdą z architektur mają podobną jakość, jedynie ostatnia warstwa kwalifikacyjna jest różnej jakości.  Jednakże tak nie jest, protokół BLUFR uwidacznia większe różnice w wynikach. Na prowadzenie wysuwa się SphereFace-64, a dopiero po nim są Fudan i FaceResNet. Warto zauważyć, że różnica 0.7% w LFW przeskalował się na różnicę 16% w protokole BLUFR-FAR 1% (porównując CASIA i SphereFace-64).<br>
Gdy weźmiemy pod uwagę podstawowe architektury, wówczas Fudan-Full wygrywa w każdym z analizowanych benchmarków. Jednakże widać, że DropOut znacząco poprawia jakość architektur, przede wszystkim poprzez zmniejszenia przeuczenia sieci. Do dokładniejszej analizy dodatków do archtektór przejdziemy w dalszy postach.</p>
<p>Jeżeli porównamy czas potrzebny do uzyskania dobrego rezultatu, tutaj zdecydowanie najlepiej wypada FaceResNet-dropout, który jest tylko nieznacznie słabszy niż najlepszy model, ale uczył się prawie 3x krócej. Dlatego właśnie <strong>FaceResNet</strong> (bez dropout) zostanie wybrany jako bazowa architektura do dalszych eksperymentów, wraz z podstawowym wynikiem (<code>baseline</code>), który będziemy chcieli poprawić.</p>
<h1 id="codalej">Co dalej?</h1>
<p>Patrząć ogólnie na wyniki, widać, że można osiągnąć wynik ~98% na LFW wykorzystując jedynie podstawowe techniki nauki sieci. Jeszcze 3 lata temu byłby to bardzo dobry wynik, obecnie wielu naukowców zaproponowało dodatkowe techniki zwiększające możliwości architektur. Czy na pewno one działają oraz czy jakiego zysku możemy się spodziewać? Tego dowiemy się w kolejnych postach, a w najbliżysz przyjrzymy się przygotowaniu danych uczących.</p>
</div>
            </section>


            <footer class="post-full-footer">

                <section class="author-card">
                    <section class="author-card-content">
                        <h4 class="author-card-name"><a href="../author/bartosz/">Bartosz Ludwiczuk</a></h4>
                            <p>Read <a href="../author/bartosz/">more posts</a> by this author.</p>
                    </section>
                </section>
                <div class="post-full-footer-right">
                    <a class="author-card-button" href="../author/bartosz/">Read More</a>
                </div>

            </footer>


        </article>

    </div>
</main>

<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">


                <article class="post-card post">
        <a class="post-card-image-link" href="../demystifain-face-recognition-part-1/">
            <div class="post-card-image" style="background-image: url(../content/images/2017/10/Face-Recognition-Pipeline---Page-1-.png)"></div>
        </a>
    <div class="post-card-content">
        <a class="post-card-content-link" href="../demystifain-face-recognition-part-1/">
            <header class="post-card-header">
                <h2 class="post-card-title">Demystifying Face Recognition: Introduction</h2>
            </header>
            <section class="post-card-excerpt">
                <p>Wstęp W internecie można znaleźć dużą liczbę artykułów oraz materiałów  przedstawiającą technikę rozpoznawania twarzy. Większość z nich opiera się na wytłumaczeniu pipeline rozpoznawania wraz z wykorzystam przygotowanych, open-source bibliotek. Dobrymi przykładami materiałów jest</p>
            </section>
        </a>
        <footer class="post-card-meta">
            <span class="post-card-author"><a href="../author/bartosz/">Bartosz Ludwiczuk</a></span>
        </footer>
    </div>
</article>

        </div>
    </div>
</aside>

<div class="floating-header">
    <div class="floating-header-logo">
        <a href="../">
            <span>BLCV</span>
        </a>
    </div>
    <span class="floating-header-divider">—</span>
    <div class="floating-header-title">Demystifying Face Recognition I: Baseline</div>
    <div class="floating-header-share">
        <div class="floating-header-share-label">Share this <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
    <path d="M7.5 15.5V4a1.5 1.5 0 1 1 3 0v4.5h2a1 1 0 0 1 1 1h2a1 1 0 0 1 1 1H18a1.5 1.5 0 0 1 1.5 1.5v3.099c0 .929-.13 1.854-.385 2.748L17.5 23.5h-9c-1.5-2-5.417-8.673-5.417-8.673a1.2 1.2 0 0 1 1.76-1.605L7.5 15.5zm6-6v2m-3-3.5v3.5m6-1v2"></path>
</svg>
</div>
        <a class="floating-header-share-tw" href="https://twitter.com/share?text=Demystifying%20Face%20Recognition%20I%3A%20Baseline&amp;url=http://localhost:2368/demystifying-face-recognition-i-baseline/" onclick="window.open(this.href, 'share-twitter', 'width=550,height=235');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"></path></svg>
        </a>
        <a class="floating-header-share-fb" href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:2368/demystifying-face-recognition-i-baseline/" onclick="window.open(this.href, 'share-facebook','width=580,height=296');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"></path></svg>
        </a>
    </div>
    <progress class="progress" value="0">
        <div class="progress-container">
            <span class="progress-bar"></span>
        </div>
    </progress>
</div>




        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="../">BLCV</a> © 2017</section>
                <nav class="site-footer-nav">
                    <a href="../">Latest Posts</a>
                    
                    
                    <a href="https://ghost.org" target="_blank">Ghost</a>
                </nav>
            </div>
        </footer>

    </div>


    <script src="https://code.jquery.com/jquery-3.2.1.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous">
    </script>
    <script type="text/javascript" src="../assets/js/jquery.fitvids.js?v=503d750ec5"></script>


    <script>

// NOTE: Scroll performance is poor in Safari
// - this appears to be due to the events firing much more slowly in Safari.
//   Dropping the scroll event and using only a raf loop results in smoother
//   scrolling but continuous processing even when not scrolling
$(document).ready(function () {
    // Start fitVids
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
    // End fitVids

    var progressBar = document.querySelector('progress');
    var header = document.querySelector('.floating-header');
    var title = document.querySelector('.post-full-title');

    var lastScrollY = window.scrollY;
    var lastWindowHeight = window.innerHeight;
    var lastDocumentHeight = $(document).height();
    var ticking = false;

    function onScroll() {
        lastScrollY = window.scrollY;
        requestTick();
    }

    function onResize() {
        lastWindowHeight = window.innerHeight;
        lastDocumentHeight = $(document).height();
        requestTick();
    }

    function requestTick() {
        if (!ticking) {
            requestAnimationFrame(update);
        }
        ticking = true;
    }

    function update() {
        var trigger = title.getBoundingClientRect().top + window.scrollY;
        var triggerOffset = title.offsetHeight + 35;
        var progressMax = lastDocumentHeight - lastWindowHeight;

        // show/hide floating header
        if (lastScrollY >= trigger + triggerOffset) {
            header.classList.add('floating-active');
        } else {
            header.classList.remove('floating-active');
        }

        progressBar.setAttribute('max', progressMax);
        progressBar.setAttribute('value', lastScrollY);

        ticking = false;
    }

    window.addEventListener('scroll', onScroll, {passive: true});
    window.addEventListener('resize', onResize, false);

    update();
});
</script>


    

</body>
